# Прогнозирование стоимости бриллиантов (Diamond Price Prediction Dataset)
Ссылка на dataset (https://www.kaggle.com/datasets/shivam2503/diamonds).
Набор данных содержит информацию о `53940` бриллиантах, включая их характеристики и цену в долларах США.
## Характеристики:
Набор данных состоит из `10` столбцов: 9 признаков и 1 целевая переменная (`Цена`).
## Признаки: 
- `carat`: Вес бриллианта в каратах.
- `cut`: Качество огранки. Категориальный признак с пятью значениями: `Fair`, `Good`, `Very Good`, `Premium`, `Ideal`.
- `color`: Цвет бриллианта со значениями: `G`, `E`, `F`, `H`, `D`, `I`, `J`.
- `clarity`: Чистота бриллианта, указывающая на наличие внутренних и внешних изъянов (включений и царапин). Категориальный признак с восемью значениями: `I1`, `SI2`, `SI1`, `VS2`, `VS1`, `VVS2`, `VVS1`, `IF`.
- `depth`: Процент глубины бриллианта, вычисляется по формуле: $$
\text{depth} = \frac{z}{\text{mean}(x, y)} = \frac{2z}{x + y}.
$$
- `table`: Ширина верхней грани бриллианта в процентах от его среднего диаметра.
- `x`: Длина бриллианта в миллиметрах.
- `y`: Ширина бриллианта в миллиметрах.
- `z`: Глубина бриллианта в миллиметрах.
## Целевая переменная: 
- `price`: Цена бриллианта в долларах США (диапазон от 326 до 18,823 долларов США).
## Разведочный анализ данных
- Целевая переменная имеет асимметричное распределение, отличное от нормального (`обратное распределение Гаусса`).
- В данных есть большое количество бриллиантов с высокой стоимостью (превышают `Q3 + 1.5 * IQR`).
- Среднее, медиана и мода не равны. Правило 3 сигм не выполняется.
- Коэффициент асимметрии больше нуля - это означает, что данные `смещены влево`, а `хвост распределения вытянут вправо`. Коэффициент эксцесса больше нуля - это означает, что распределение имеет более `острый пик` и более `тяжёлые хвосты`.
- Для прогнозирования необходимо использовать устойчивые регрессионные модели. Поэтому в качестве функции потерь была выбрана `MAE`.
## Обработка данных
- Удалил строки с пропусками.
- Удалил строки с дубликатами.
- Удалил факторы, которые имели слабую зависимость с целевой переменной (`Глубина`, `Площадка`), и те которые образовывали мультиколлинеарность (`Длина`, `Ширина`, `Высота`).
- Преобразовал типы данных: для количественных переменных установил тип `float32`, а для категориальных `category`.
## Эффект от обработки данных
- Доля переобучения `сократилась`, метрики стали `стабильнее`.
- У базовой модели $\frac{MAE_{\text{val}}}{MAE_{\text{train}}} \approx 1.07$, а $\frac{RMSE_{\text{val}}}{RMSE_{\text{train}}} \approx 1.14$;
У новой модели $\frac{MAE_{\text{val}}}{MAE_{\text{train}}} \approx 1.03$, а $\frac{RMSE_{\text{val}}}{RMSE_{\text{train}}} \approx 1.03$.
- Сократилось количество `завышенных` и `заниженных` прогнозов.
- У базовой модели отклонения не превышали `3 сигм`, а у новой не превышают `2 сигмы`.
## Подбор гиперпараметров модели
- В начале было зафиксировано: `objective` = `mae`.
- Стартовое количество деревьев (`n_estimators`) было подобрано с помощью замера метрики (`MAE`) на валидационной выборке с критерием останова `early_stopping_rounds` = 50. Оно равнялось `442`.
- Количество листов в дереве (`num_leaves`) было подобрано с помощью замера метрики на валидационной выборке. Значения были в диапазоне от `7` до `50`. Лучшим оказалось `43`.
- Параметры сэмплирования относительно столбцов (`colsample_bytree`) и строк (`subsample`) подбирались таким же образом. Оптимальные значения - `subsample` = 0.8, `colsample_bytree` = 0.9.
- Скорректировал количество деревьев (`n_estimators`) - оптимальным оказалось число `454`.
## Эффект от подбора гиперпараметров модели
- Ошибка `MAPE` на валидационной выборке сократилась до `7.228` %, а была `7.982` %.
- Количество отклонений в окрестности нуля на гистограмме распределения увеличилось.
## Метрики итоговой модели на обучающей и тестовой выборке
| Метрика | Train | Test|
|:------:|:---------:|:-------:|
| RMSE |   524.603   |  535.837 |
| MAE |   254.852 |  267.931 |
| MAPE |   6.997  |  7.388 |
| R² adjusted  |   0.983  |  0.981 |